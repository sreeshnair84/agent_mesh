# Skill Creation Reference
# This file provides examples for creating reusable skills in Agent Mesh

# Basic Skill Configuration
apiVersion: v1
kind: Skill
metadata:
  name: web_search
  display_name: Web Search
  description: Search the internet for information using various search engines
  category: research
  version: "1.0.0"
  tags:
    - search
    - research
    - web
    - information

# Skill Specification
spec:
  # Skill Type and Configuration
  type: api_integration
  
  # Configuration parameters
  config:
    search_engine: google
    max_results: 10
    safe_search: true
    result_format: json
    timeout: 30
    
  # Input/Output Schema
  input_schema:
    type: object
    properties:
      query:
        type: string
        description: The search query
        required: true
      limit:
        type: integer
        description: Maximum number of results
        default: 10
        minimum: 1
        maximum: 50
      language:
        type: string
        description: Language preference
        default: en
        enum: [en, es, fr, de, it, pt, ja, zh]

  output_schema:
    type: object
    properties:
      results:
        type: array
        items:
          type: object
          properties:
            title:
              type: string
            url:
              type: string
            snippet:
              type: string
            domain:
              type: string
      total_results:
        type: integer
      search_time:
        type: number

  # Dependencies
  dependencies:
    - http_client
    - json_parser
    - url_validator

  # Usage Examples
  examples:
    - name: Basic Search
      description: Simple web search
      input:
        query: "artificial intelligence trends 2024"
        limit: 5
      expected_output:
        results:
          - title: "AI Trends 2024"
            url: "https://example.com/ai-trends"
            snippet: "Latest trends in AI..."
            domain: "example.com"
        total_results: 5
        search_time: 0.5

    - name: Multilingual Search
      description: Search in different language
      input:
        query: "inteligencia artificial"
        language: es
        limit: 3

  # Error Handling
  error_handling:
    rate_limit_exceeded:
      action: retry_with_backoff
      max_retries: 3
      backoff_seconds: [1, 2, 4]
    
    api_unavailable:
      action: fallback_search_engine
      fallback_options: [bing, duckduckgo]
    
    invalid_query:
      action: return_error
      error_message: "Invalid search query provided"

  # Performance Metrics
  performance:
    typical_response_time: 500 # milliseconds
    max_response_time: 5000 # milliseconds
    success_rate: 0.99
    rate_limit: 1000 # requests per hour

---
# Code Generation Skill
apiVersion: v1
kind: Skill
metadata:
  name: code_generation
  display_name: Code Generation
  description: Generate code in various programming languages
  category: development
  version: "1.2.0"
  tags:
    - code
    - programming
    - development
    - generation

spec:
  type: function_execution
  
  config:
    supported_languages:
      - python
      - javascript
      - typescript
      - java
      - cpp
      - csharp
      - go
      - rust
    
    code_quality_checks: true
    syntax_validation: true
    best_practices: true
    documentation_generation: true

  input_schema:
    type: object
    properties:
      language:
        type: string
        description: Programming language
        enum: [python, javascript, typescript, java, cpp, csharp, go, rust]
        required: true
      
      task_description:
        type: string
        description: Description of the code to generate
        required: true
      
      style_guide:
        type: string
        description: Code style preference
        enum: [pep8, google, airbnb, standard]
        default: standard
      
      include_tests:
        type: boolean
        description: Whether to include unit tests
        default: false
      
      include_documentation:
        type: boolean
        description: Whether to include documentation
        default: true

  output_schema:
    type: object
    properties:
      code:
        type: string
        description: Generated code
      
      tests:
        type: string
        description: Unit tests (if requested)
      
      documentation:
        type: string
        description: Code documentation
      
      dependencies:
        type: array
        items:
          type: string
        description: Required dependencies
      
      complexity_score:
        type: number
        description: Code complexity score
      
      quality_metrics:
        type: object
        properties:
          maintainability: { type: number }
          readability: { type: number }
          performance: { type: number }

  dependencies:
    - code_analyzer
    - syntax_validator
    - test_generator
    - documentation_generator

  examples:
    - name: Python Function
      description: Generate a Python function
      input:
        language: python
        task_description: "Create a function to calculate fibonacci numbers"
        include_tests: true
        include_documentation: true
      
    - name: JavaScript API
      description: Generate REST API endpoint
      input:
        language: javascript
        task_description: "Create an Express.js API endpoint for user authentication"
        style_guide: airbnb
        include_tests: true

  error_handling:
    unsupported_language:
      action: return_error
      error_message: "Language not supported"
    
    invalid_task:
      action: request_clarification
      clarification_prompt: "Please provide more specific requirements"
    
    generation_failed:
      action: retry_with_simpler_approach
      max_retries: 2

---
# Data Analysis Skill
apiVersion: v1
kind: Skill
metadata:
  name: data_analysis
  display_name: Data Analysis
  description: Analyze and visualize data from various sources
  category: analysis
  version: "1.1.0"
  tags:
    - data
    - analysis
    - visualization
    - statistics

spec:
  type: data_processing
  
  config:
    supported_formats:
      - csv
      - json
      - xlsx
      - parquet
      - sql
    
    max_file_size: 100MB
    chart_types:
      - line
      - bar
      - scatter
      - histogram
      - heatmap
      - pie
    
    statistical_tests:
      - t_test
      - chi_square
      - correlation
      - regression
      - anova

  input_schema:
    type: object
    properties:
      data_source:
        type: string
        description: Data source (file path or URL)
        required: true
      
      analysis_type:
        type: string
        description: Type of analysis to perform
        enum: [descriptive, inferential, predictive, diagnostic]
        required: true
      
      visualization_type:
        type: string
        description: Type of visualization
        enum: [line, bar, scatter, histogram, heatmap, pie]
      
      columns:
        type: array
        items:
          type: string
        description: Columns to analyze
      
      filters:
        type: object
        description: Data filters to apply
      
      statistical_tests:
        type: array
        items:
          type: string
        description: Statistical tests to run

  output_schema:
    type: object
    properties:
      summary_statistics:
        type: object
        description: Descriptive statistics
      
      visualization:
        type: string
        description: Base64 encoded chart image
      
      insights:
        type: array
        items:
          type: string
        description: Key insights from analysis
      
      recommendations:
        type: array
        items:
          type: string
        description: Recommendations based on analysis
      
      statistical_results:
        type: object
        description: Results of statistical tests

  dependencies:
    - pandas
    - matplotlib
    - seaborn
    - numpy
    - scipy
    - plotly

  examples:
    - name: Sales Data Analysis
      description: Analyze sales performance data
      input:
        data_source: "sales_data.csv"
        analysis_type: descriptive
        visualization_type: line
        columns: ["date", "sales", "region"]
    
    - name: Customer Segmentation
      description: Perform customer segmentation analysis
      input:
        data_source: "customer_data.json"
        analysis_type: predictive
        visualization_type: scatter
        statistical_tests: ["correlation", "t_test"]

  performance:
    typical_processing_time: 2000 # milliseconds
    max_processing_time: 30000 # milliseconds
    memory_usage: 512MB
    success_rate: 0.95

---
# Text Summarization Skill
apiVersion: v1
kind: Skill
metadata:
  name: text_summarization
  display_name: Text Summarization
  description: Summarize long text documents into concise summaries
  category: content
  version: "1.0.0"
  tags:
    - text
    - summarization
    - content
    - nlp

spec:
  type: nlp_processing
  
  config:
    max_input_length: 50000 # characters
    summary_lengths:
      short: 100 # words
      medium: 300 # words
      long: 500 # words
    
    summary_types:
      - extractive
      - abstractive
      - hybrid
    
    supported_formats:
      - plain_text
      - markdown
      - html
      - pdf

  input_schema:
    type: object
    properties:
      text:
        type: string
        description: Text to summarize
        required: true
      
      summary_length:
        type: string
        description: Desired summary length
        enum: [short, medium, long]
        default: medium
      
      summary_type:
        type: string
        description: Type of summary
        enum: [extractive, abstractive, hybrid]
        default: abstractive
      
      key_topics:
        type: array
        items:
          type: string
        description: Key topics to focus on
      
      format:
        type: string
        description: Input format
        enum: [plain_text, markdown, html, pdf]
        default: plain_text

  output_schema:
    type: object
    properties:
      summary:
        type: string
        description: Generated summary
      
      key_points:
        type: array
        items:
          type: string
        description: Key points extracted
      
      entities:
        type: array
        items:
          type: object
          properties:
            entity: { type: string }
            type: { type: string }
            relevance: { type: number }
      
      sentiment:
        type: string
        description: Overall sentiment
        enum: [positive, negative, neutral]
      
      word_count:
        type: integer
        description: Summary word count
      
      compression_ratio:
        type: number
        description: Compression ratio (original/summary)

  dependencies:
    - transformers
    - spacy
    - nltk
    - textstat

  examples:
    - name: Article Summary
      description: Summarize a news article
      input:
        text: "Long news article text..."
        summary_length: medium
        summary_type: abstractive
    
    - name: Research Paper Summary
      description: Summarize research paper
      input:
        text: "Research paper content..."
        summary_length: long
        summary_type: hybrid
        key_topics: ["methodology", "results", "conclusion"]

  error_handling:
    text_too_long:
      action: chunk_and_summarize
      chunk_size: 10000
    
    empty_input:
      action: return_error
      error_message: "Input text is empty"
    
    processing_failed:
      action: fallback_to_extractive
      fallback_method: extractive

  performance:
    typical_response_time: 3000 # milliseconds
    max_response_time: 15000 # milliseconds
    accuracy: 0.85
    coherence_score: 0.78
